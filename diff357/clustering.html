
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.17.1: http://docutils.sourceforge.net/" name="generator"/>
<title>9. Clustering — Data Science: A First Introduction with Python</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet"/>
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet"/>
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet"/>
<link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet"/>
<link as="font" crossorigin="" href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" rel="stylesheet" type="text/css"/>
<link href="_static/togglebutton.css" rel="stylesheet" type="text/css"/>
<link href="_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css"/>
<link href="_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="_static/style.css" rel="stylesheet" type="text/css"/>
<link href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" rel="preload"/>
<link as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" rel="preload"/>
<script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>
<script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
<script src="_static/jquery.js"></script>
<script src="_static/underscore.js"></script>
<script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="_static/doctools.js"></script>
<script src="_static/clipboard.min.js"></script>
<script src="_static/copybutton.js"></script>
<script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="_static/togglebutton.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="_static/design-tabs.js"></script>
<script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-7XBFF4RSN2"></script>
<script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-7XBFF4RSN2');
            </script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="_static/sphinx-thebe.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'clustering';</script>
<link href="genindex.html" rel="index" title="Index"/>
<link href="search.html" rel="search" title="Search"/>
<link href="inference.html" rel="next" title="10. Statistical inference"/>
<link href="regression2.html" rel="prev" title="8. Regression II: linear regression"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<script src="website_diff.js"></script><link href="website_diff.css" rel="stylesheet" type="text/css"/></head>
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<a class="skip-link" href="#main-content">Skip to main content</a>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar">
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<a class="navbar-brand logo" href="index.html">
<p class="title logo__title">Data Science: A First Introduction with Python</p>
</a></div>
<div class="sidebar-primary-item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Front Matter</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal link-to-diff" href="preface-text.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="foreword-text.html">Foreword</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgements.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">About the authors</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal link-to-diff" href="intro.html">1. Python and Pandas</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="reading.html">2. Reading in data locally and from the web</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="wrangling.html">3. Cleaning and wrangling data</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="viz.html">4. Effective data visualization</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="classification1.html">5. Classification I: training &amp; predicting</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="classification2.html">6. Classification II: evaluation &amp; tuning</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="regression1.html">7. Regression I: K-nearest neighbors</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="regression2.html">8. Regression II: linear regression</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">9. Clustering</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="inference.html">10. Statistical inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="jupyter.html">11. Combining code and text with Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="version-control.html">12. Collaboration with version control</a></li>
<li class="toctree-l1"><a class="reference internal link-to-diff" href="setup.html">13. Setting up your computer</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" data-bs-placement="bottom" data-bs-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label></div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="article-header-buttons">
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm btn-download-source-button dropdown-item" data-bs-placement="left" data-bs-toggle="tooltip" href="_sources/clustering.md" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.md</span>
</a>
</li>
<li>
<button class="btn btn-sm btn-download-pdf-button dropdown-item" data-bs-placement="left" data-bs-toggle="tooltip" onclick="window.print()" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
<button class="btn btn-sm btn-fullscreen-button" data-bs-placement="bottom" data-bs-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-bs-placement="bottom" data-bs-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div></div>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Clustering</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">9.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-learning-objectives">9.2. Chapter learning objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">9.3. Clustering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-illustrative-example">9.4. An illustrative example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">9.5. K-means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-cluster-quality">9.5.1. Measuring cluster quality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-clustering-algorithm">9.5.2. The clustering algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-restarts">9.5.3. Random restarts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-k">9.5.4. Choosing K</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means-in-python">9.6. K-means in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">9.7. Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-resources">9.8. Additional resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">9.9. References</a></li>
</ul>
</nav>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" role="main">
<section class="tex2jax_ignore mathjax_ignore" id="clustering">
<span id="id1"></span><h1><span class="section-number">9. </span>Clustering<a class="headerlink" href="#clustering" title="Permalink to this heading">#</a></h1>
<section id="overview">
<h2><span class="section-number">9.1. </span>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>As part of exploratory data analysis, it is often helpful to see if there are
meaningful subgroups (or <em>clusters</em>) in the data.
This grouping can be used for many purposes,
such as generating new questions or improving predictive analyses.
This chapter provides an introduction to clustering
using the K-means algorithm,
including techniques to choose the number of clusters.</p>
</section>
<section id="chapter-learning-objectives">
<h2><span class="section-number">9.2. </span>Chapter learning objectives<a class="headerlink" href="#chapter-learning-objectives" title="Permalink to this heading">#</a></h2>
<p>By the end of the chapter, readers will be able to do the following:</p>
<ul class="simple">
<li><p>Describe a situation in which clustering is an appropriate technique to use,
and what insight it might extract from the data.</p></li>
<li><p>Explain the K-means clustering algorithm.</p></li>
<li><p>Interpret the output of a K-means analysis.</p></li>
<li><p>Differentiate between clustering, classification, and regression.</p></li>
<li><p>Identify when it is necessary to scale variables before clustering, and do this using Python.</p></li>
<li><p>Perform K-means clustering in Python using <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>.</p></li>
<li><p>Use the elbow method to choose the number of clusters for K-means.</p></li>
<li><p>Visualize the output of K-means clustering in Python using a colored scatter plot.</p></li>
<li><p>Describe advantages, limitations and assumptions of the K-means clustering algorithm.</p></li>
</ul>
</section>
<section id="id2">
<h2><span class="section-number">9.3. </span>Clustering<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p id="index-0">Clustering is a data analysis task
involving separating a data set into subgroups of related data.
For example, we might use clustering to separate a
data set of documents into groups that correspond to topics, a data set of
human genetic information into groups that correspond to ancestral
subpopulations, or a data set of online customers into groups that correspond
to purchasing behaviors.  Once the data are separated, we can, for example,
use the subgroups to generate new questions about the data and follow up with a
predictive modeling exercise. In this course, clustering will be used only for
exploratory analysis, i.e., uncovering patterns in the data.</p>
<p id="index-1">Note that clustering is a fundamentally different kind of task than
classification or regression.  In particular, both classification and
regression are <em>supervised tasks</em> where there is a <em>response variable</em> (a
category label or value), and we have examples of past data with labels/values
that help us predict those of future data.  By contrast, clustering is an
<em>unsupervised task</em>, as we are trying to understand and examine the structure
of data without any response variable labels or values to help us.  This
approach has both advantages and disadvantages.  Clustering requires no
additional annotation or input on the data.  For example, while it would be
nearly impossible to annotate all the articles on Wikipedia with human-made
topic labels, we can cluster the articles without this information to find
groupings corresponding to topics automatically.  However, given that there is
no response variable, it is not as easy to evaluate the “quality” of a
clustering.  With classification, we can use a test data set to assess
prediction performance. In clustering, there is not a single good choice for
evaluation. In this book, we will use visualization to ascertain the quality of
a clustering, and leave rigorous evaluation for more advanced courses.</p>
<p>Given that there is no response variable, it is not as easy to evaluate
the “quality” of a clustering.  With classification, we can use a test data set
to assess prediction performance. In clustering, there is not a single good
choice for evaluation. In this book, we will use visualization to ascertain the
quality of a clustering, and leave rigorous evaluation for more advanced
courses.</p>
<p id="index-2">As in the case of classification,
there are many possible methods that we could use to cluster our observations
to look for subgroups.
In this book, we will focus on the widely used K-means algorithm <span id="id3">[<a class="reference internal" href="#id12" title="Stuart Lloyd. Least square quantization in PCM. IEEE Transactions on Information Theory, 28(2):129–137, 1982. Originally released as a Bell Telephone Laboratories Paper in 1957.">Lloyd, 1982</a>]</span>.
In your future studies, you might encounter hierarchical clustering,
principal component analysis, multidimensional scaling, and more;
see the additional resources section at the end of this chapter
for where to begin learning more about these other methods.</p>
<div class="admonition note" id="index-3">
<p class="admonition-title">Note</p>
<p>There are also so-called <em>semisupervised</em> tasks,
where only some of the data come with response variable labels/values,
but the vast majority don’t.
The goal is to try to uncover underlying structure in the data
that allows one to guess the missing labels.
This sort of task is beneficial, for example,
when one has an unlabeled data set that is too large to manually label,
but one is willing to provide a few informative example labels as a “seed”
to guess the labels for all the data.</p>
</div>
</section>
<section id="an-illustrative-example">
<h2><span class="section-number">9.4. </span>An illustrative example<a class="headerlink" href="#an-illustrative-example" title="Permalink to this heading">#</a></h2>
<p id="index-4">In this chapter we will focus on a data set from
<a class="reference external" href="https://allisonhorst.github.io/palmerpenguins/">the <code class="docutils literal notranslate"><span class="pre">palmerpenguins</span></code> R package</a> <span id="id4">[<a class="reference internal" href="#id41" title="Allison Horst, Alison Hill, and Kristen Gorman. palmerpenguins: Palmer Archipelago penguin data. 2020. R package version 0.1.0. URL: https://allisonhorst.github.io/palmerpenguins/.">Horst <em>et al.</em>, 2020</a>]</span>. This
data set was collected by Dr. Kristen Gorman and
the Palmer Station, Antarctica Long Term Ecological Research Site, and includes
measurements for adult penguins (<a class="reference internal" href="#penguins"><span class="std std-numref">Fig. 9.1</span></a>) found near there <span id="id5">[<a class="reference internal" href="#id11" title="Kristen Gorman, Tony Williams, and William Fraser. Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus pygoscelis). PLoS ONE, 2014.">Gorman <em>et al.</em>, 2014</a>]</span>.
Our goal will be to use two
variables—penguin bill and flipper length, both in millimeters—to determine whether
there are distinct types of penguins in our data.
Understanding this might help us with species discovery and classification in a data-driven
way. Note that we have reduced the size of the data set to 18 observations and 2 variables;
this will help us make clear visualizations that illustrate how clustering works for learning purposes.</p>
<figure class="align-default" id="penguins">
<a class="reference internal image-reference" href="_images/gentoo.jpg"><img alt="_images/gentoo.jpg" src="_images/gentoo.jpg" style="height: 400px;"/></a>
<figcaption>
<p><span class="caption-number">Fig. 9.1 </span><span class="caption-text">A Gentoo penguin.</span><a class="headerlink" href="#penguins" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Before we get started, we will set a random seed.
This will ensure that our analysis will be reproducible.
As we will learn in more detail later in the chapter,
setting the seed here is important
because the K-means clustering algorithm uses randomness
when choosing a starting position for each cluster.</p>
<div class="cell docutils container" id="index-5">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p id="index-6">Now we can load and preview the <code class="docutils literal notranslate"><span class="pre">penguins</span></code> data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">penguins</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">"data/penguins.csv"</span><span class="p">)</span>
<span class="n">penguins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>bill_length_mm</th>
<th>flipper_length_mm</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>39.2</td>
<td>196</td>
</tr>
<tr>
<th>1</th>
<td>36.5</td>
<td>182</td>
</tr>
<tr>
<th>2</th>
<td>34.5</td>
<td>187</td>
</tr>
<tr>
<th>3</th>
<td>36.7</td>
<td>187</td>
</tr>
<tr>
<th>4</th>
<td>38.1</td>
<td>181</td>
</tr>
<tr>
<th>5</th>
<td>39.2</td>
<td>190</td>
</tr>
<tr>
<th>6</th>
<td>36.0</td>
<td>195</td>
</tr>
<tr>
<th>7</th>
<td>37.8</td>
<td>193</td>
</tr>
<tr>
<th>8</th>
<td>46.5</td>
<td>213</td>
</tr>
<tr>
<th>9</th>
<td>46.1</td>
<td>215</td>
</tr>
<tr>
<th>10</th>
<td>47.8</td>
<td>215</td>
</tr>
<tr>
<th>11</th>
<td>45.0</td>
<td>220</td>
</tr>
<tr>
<th>12</th>
<td>49.1</td>
<td>212</td>
</tr>
<tr>
<th>13</th>
<td>43.3</td>
<td>208</td>
</tr>
<tr>
<th>14</th>
<td>46.0</td>
<td>195</td>
</tr>
<tr>
<th>15</th>
<td>46.7</td>
<td>195</td>
</tr>
<tr>
<th>16</th>
<td>52.2</td>
<td>197</td>
</tr>
<tr>
<th>17</th>
<td>46.8</td>
<td>189</td>
</tr>
</tbody>
</table>
</div></div></div>
</div>
<p>We will begin by using a version of the data that we have standardized, <code class="docutils literal notranslate"><span class="pre">penguins_standardized</span></code>,
to illustrate how K-means clustering works (recall standardization from <a class="reference internal link-to-diff" href="classification1.html#classification1"><span class="std std-numref">Chapter 5</span></a>).
Later in this chapter, we will return to the original <code class="docutils literal notranslate"><span class="pre">penguins</span></code> data to see how to include standardization automatically
in the clustering pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins_standardized</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>bill_length_standardized</th>
<th>flipper_length_standardized</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>-0.641361</td>
<td>-0.189773</td>
</tr>
<tr>
<th>1</th>
<td>-1.144917</td>
<td>-1.328412</td>
</tr>
<tr>
<th>2</th>
<td>-1.517922</td>
<td>-0.921755</td>
</tr>
<tr>
<th>3</th>
<td>-1.107617</td>
<td>-0.921755</td>
</tr>
<tr>
<th>4</th>
<td>-0.846513</td>
<td>-1.409743</td>
</tr>
<tr>
<th>5</th>
<td>-0.641361</td>
<td>-0.677761</td>
</tr>
<tr>
<th>6</th>
<td>-1.238168</td>
<td>-0.271104</td>
</tr>
<tr>
<th>7</th>
<td>-0.902464</td>
<td>-0.433767</td>
</tr>
<tr>
<th>8</th>
<td>0.720106</td>
<td>1.192860</td>
</tr>
<tr>
<th>9</th>
<td>0.645505</td>
<td>1.355522</td>
</tr>
<tr>
<th>10</th>
<td>0.962559</td>
<td>1.355522</td>
</tr>
<tr>
<th>11</th>
<td>0.440353</td>
<td>1.762179</td>
</tr>
<tr>
<th>12</th>
<td>1.205012</td>
<td>1.111528</td>
</tr>
<tr>
<th>13</th>
<td>0.123299</td>
<td>0.786203</td>
</tr>
<tr>
<th>14</th>
<td>0.626855</td>
<td>-0.271104</td>
</tr>
<tr>
<th>15</th>
<td>0.757407</td>
<td>-0.271104</td>
</tr>
<tr>
<th>16</th>
<td>1.783170</td>
<td>-0.108442</td>
</tr>
<tr>
<th>17</th>
<td>0.776057</td>
<td>-0.759092</td>
</tr>
</tbody>
</table>
</div></div></div>
</div>
<p>Next, we can create a scatter plot using this data set
to see if we can detect subtypes or groups in our data set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>

<span class="n">scatter_plot</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">penguins_standardized</span><span class="p">)</span><span class="o">.</span><span class="n">mark_circle</span><span class="p">()</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">"flipper_length_standardized"</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Flipper Length (standardized)"</span><span class="p">),</span>
    <span class="n">y</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s2">"bill_length_standardized"</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Bill Length (standardized)"</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="scatter-plot" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-92645118b1bd4976a9bc1da4fb085b87.vega-embed</ins><del>#altair-viz-5020cc9426ca4143ae20a08221eec21b.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-92645118b1bd4976a9bc1da4fb085b87.vega-embed</ins><del>#altair-viz-5020cc9426ca4143ae20a08221eec21b.vega-embed</del> details,
  <ins>#altair-viz-92645118b1bd4976a9bc1da4fb085b87.vega-embed</ins><del>#altair-viz-5020cc9426ca4143ae20a08221eec21b.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-92645118b1bd4976a9bc1da4fb085b87"><div id="altair-viz-5020cc9426ca4143ae20a08221eec21b"></div><img src="prerendered/scatter-plot.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.2 </span><span class="caption-text">Scatter plot of standardized bill length versus standardized flipper length.</span><a class="headerlink" href="#scatter-plot" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p id="index-7">Based on the visualization in <a class="reference internal" href="#scatter-plot"><span class="std std-numref">Fig. 9.2</span></a>,
we might suspect there are a few subtypes of penguins within our data set.
We can see roughly 3 groups of observations in <a class="reference internal" href="#scatter-plot"><span class="std std-numref">Fig. 9.2</span></a>,
including:</p>
<ol class="arabic simple">
<li><p>a small flipper and bill length group,</p></li>
<li><p>a small flipper length, but large bill length group, and</p></li>
<li><p>a large  flipper and bill length group.</p></li>
</ol>
<p id="index-8">Data visualization is a great tool to give us a rough sense of such patterns
when we have a small number of variables.
But if we are to group data—and select the number of groups—as part of
a reproducible analysis, we need something a bit more automated.
Additionally, finding groups via visualization becomes more difficult
as we increase the number of variables we consider when clustering.
The way to rigorously separate the data into groups
is to use a clustering algorithm.
In this chapter, we will focus on the <em>K-means</em> algorithm,
a widely used and often very effective clustering method,
combined with the <em>elbow method</em>
for selecting the number of clusters.
This procedure will separate the data into groups;
<a class="reference internal" href="#colored-scatter-plot"><span class="std std-numref">Fig. 9.3</span></a> shows these groups
denoted by colored scatter points.</p>
<figure class="align-default" id="colored-scatter-plot" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-89942617f2b74538b0734f259fdd23cf.vega-embed</ins><del>#altair-viz-4f42427fd09e4f02aa11c4d248694e8d.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-89942617f2b74538b0734f259fdd23cf.vega-embed</ins><del>#altair-viz-4f42427fd09e4f02aa11c4d248694e8d.vega-embed</del> details,
  <ins>#altair-viz-89942617f2b74538b0734f259fdd23cf.vega-embed</ins><del>#altair-viz-4f42427fd09e4f02aa11c4d248694e8d.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-89942617f2b74538b0734f259fdd23cf"><div id="altair-viz-4f42427fd09e4f02aa11c4d248694e8d"></div><img src="prerendered/colored-scatter-plot.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.3 </span><span class="caption-text">Scatter plot of standardized bill length versus standardized flipper length with colored groups.</span><a class="headerlink" href="#colored-scatter-plot" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p>What are the labels for these groups? Unfortunately, we don’t have any. K-means,
like almost all clustering algorithms, just outputs meaningless “cluster labels”
that are typically whole numbers: 0, 1, 2, 3, etc. But in a simple case like this,
where we can easily visualize the clusters on a scatter plot, we can give
human-made labels to the groups using their positions on
the plot:</p>
<ul class="simple">
<li><p>small flipper length and small bill length (<font color="#f59518">orange cluster</font>),</p></li>
<li><p>small flipper length and large bill length (<font color="#4c78a8">blue cluster</font>).</p></li>
<li><p>and large flipper length and large bill  length (<font color="#e45756">red cluster</font>).</p></li>
</ul>
<p>Once we have made these determinations, we can use them to inform our species
classifications or ask further questions about our data. For example, we might
be interested in understanding the relationship between flipper length and bill
length, and that relationship may differ depending on the type of penguin we
have.</p>
</section>
<section id="k-means">
<h2><span class="section-number">9.5. </span>K-means<a class="headerlink" href="#k-means" title="Permalink to this heading">#</a></h2>
<section id="measuring-cluster-quality">
<h3><span class="section-number">9.5.1. </span>Measuring cluster quality<a class="headerlink" href="#measuring-cluster-quality" title="Permalink to this heading">#</a></h3>
<span class="target" id="index-9"></span><p id="index-10">The K-means algorithm is a procedure that groups data into K clusters.
It starts with an initial clustering of the data, and then iteratively
improves it by making adjustments to the assignment of data
to clusters until it cannot improve any further. But how do we measure
the “quality” of a clustering, and what does it mean to improve it?
In K-means clustering, we measure the quality of a cluster by its
<em>within-cluster sum-of-squared-distances</em> (WSSD), also called <em>inertia</em>. Computing this involves two steps.
First, we find the cluster centers by computing the mean of each variable
over data points in the cluster. For example, suppose we have a
cluster containing four observations, and we are using two variables, <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>, to cluster the data.
Then we would compute the coordinates, <span class="math notranslate nohighlight">\(\mu_x\)</span> and <span class="math notranslate nohighlight">\(\mu_y\)</span>, of the cluster center via</p>
<div class="math notranslate nohighlight">
\[
\mu_x = \frac{1}{4}(x_1+x_2+x_3+x_4) \quad \mu_y = \frac{1}{4}(y_1+y_2+y_3+y_4)
\]</div>
<p>In the first cluster from the example, there are <span class="pasted-text">4</span> data points. These are shown with their cluster center
(standardized flipper length <span class="pasted-text">-0.35</span>, standardized bill length <span class="pasted-text">0.99</span>) highlighted
in <a class="reference internal" href="#toy-example-clus1-center"><span class="std std-numref">Fig. 9.4</span></a></p>
<figure class="align-default" id="toy-example-clus1-center" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-34bcb44740f8450c84dbc81a8a8739b0.vega-embed</ins><del>#altair-viz-f6657ca762704e34a56fbdccc05f319e.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-34bcb44740f8450c84dbc81a8a8739b0.vega-embed</ins><del>#altair-viz-f6657ca762704e34a56fbdccc05f319e.vega-embed</del> details,
  <ins>#altair-viz-34bcb44740f8450c84dbc81a8a8739b0.vega-embed</ins><del>#altair-viz-f6657ca762704e34a56fbdccc05f319e.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-34bcb44740f8450c84dbc81a8a8739b0"><div id="altair-viz-f6657ca762704e34a56fbdccc05f319e"></div><img src="prerendered/toy-example-clus1-center.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.4 </span><span class="caption-text">Cluster 0 from the <code class="docutils literal notranslate"><span class="pre">penguins_standardized</span></code> data set example. Observations are small blue points, with the cluster center highlighted as a large blue point with a black outline.</span><a class="headerlink" href="#toy-example-clus1-center" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p id="index-11">The second step in computing the WSSD is to add up the squared distance
between each point in the cluster
and the cluster center.
We use the straight-line / Euclidean distance formula
that we learned about in <a class="reference internal link-to-diff" href="classification1.html#classification1"><span class="std std-numref">Chapter 5</span></a>.
In the <span class="pasted-text">4</span>-observation cluster example above,
we would compute the WSSD <span class="math notranslate nohighlight">\(S^2\)</span> via</p>
<div class="math notranslate nohighlight">
\[\begin{split}
S^2 = \left((x_1 - \mu_x)^2 + (y_1 - \mu_y)^2\right) + \left((x_2 - \mu_x)^2 + (y_2 - \mu_y)^2\right)\\
 + \left((x_3 - \mu_x)^2 + (y_3 - \mu_y)^2\right)  +  \left((x_4 - \mu_x)^2 + (y_4 - \mu_y)^2\right)
\end{split}\]</div>
<p>These distances are denoted by lines in <a class="reference internal" href="#toy-example-clus1-dists"><span class="std std-numref">Fig. 9.5</span></a> for the first cluster of the penguin data example.</p>
<figure class="align-default" id="toy-example-clus1-dists" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-bbbf66c928074209b8c36e884a6d4370.vega-embed</ins><del>#altair-viz-94387dc68ccf4be9a299a6f533bcd162.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-bbbf66c928074209b8c36e884a6d4370.vega-embed</ins><del>#altair-viz-94387dc68ccf4be9a299a6f533bcd162.vega-embed</del> details,
  <ins>#altair-viz-bbbf66c928074209b8c36e884a6d4370.vega-embed</ins><del>#altair-viz-94387dc68ccf4be9a299a6f533bcd162.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-bbbf66c928074209b8c36e884a6d4370"><div id="altair-viz-94387dc68ccf4be9a299a6f533bcd162"></div><img src="prerendered/toy-example-clus1-dists.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.5 </span><span class="caption-text">Cluster 0 from the <code class="docutils literal notranslate"><span class="pre">penguins_standardized</span></code> data set example. Observations are small blue points, with the cluster center highlighted as a large blue point with a black outline. The distances from the observations to the cluster center are represented as black lines.</span><a class="headerlink" href="#toy-example-clus1-dists" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p>The larger the value of <span class="math notranslate nohighlight">\(S^2\)</span>, the more spread out the cluster is, since large <span class="math notranslate nohighlight">\(S^2\)</span> means
that points are far from the cluster center. Note, however, that “large” is relative to <em>both</em> the
scale of the variables for clustering <em>and</em> the number of points in the cluster. A cluster where points
are very close to the center might still have a large <span class="math notranslate nohighlight">\(S^2\)</span> if there are many data points in the cluster.</p>
<p>After we have calculated the WSSD for all the clusters,
we sum them together to get the <em>total WSSD</em>. For our example,
this means adding up all the squared distances for the 18 observations.
These distances are denoted by black lines in
<a class="reference internal" href="#toy-example-all-clus-dists"><span class="std std-numref">Fig. 9.6</span></a>.</p>
<figure class="align-default" id="toy-example-all-clus-dists" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-446679c0d69b4fd2b14f42e487b0934f.vega-embed</ins><del>#altair-viz-38b13ee639994e4fbb681984231cc13e.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-446679c0d69b4fd2b14f42e487b0934f.vega-embed</ins><del>#altair-viz-38b13ee639994e4fbb681984231cc13e.vega-embed</del> details,
  <ins>#altair-viz-446679c0d69b4fd2b14f42e487b0934f.vega-embed</ins><del>#altair-viz-38b13ee639994e4fbb681984231cc13e.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-446679c0d69b4fd2b14f42e487b0934f"><div id="altair-viz-38b13ee639994e4fbb681984231cc13e"></div><img src="prerendered/toy-example-all-clus-dists.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.6 </span><span class="caption-text">All clusters from the <code class="docutils literal notranslate"><span class="pre">penguins_standardized</span></code> data set example. Observations are small orange, blue, and yellow points with cluster centers denoted by larger points with a black outline. The distances from the observations to each of the respective cluster centers are represented as black lines.</span><a class="headerlink" href="#toy-example-all-clus-dists" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p>Since K-means uses the straight-line distance to measure the quality of a clustering,
it is limited to clustering based on quantitative variables.
However, note that there are variants of the K-means algorithm,
as well as other clustering algorithms entirely,
that use other distance metrics
to allow for non-quantitative data to be clustered.
These are beyond the scope of this book.</p>
</section>
<section id="the-clustering-algorithm">
<h3><span class="section-number">9.5.2. </span>The clustering algorithm<a class="headerlink" href="#the-clustering-algorithm" title="Permalink to this heading">#</a></h3>
<p id="index-12">We begin the K-means algorithm by picking K,
and randomly assigning a roughly equal number of observations
to each of the K clusters.
An example random initialization is shown in <a class="reference internal" href="#toy-kmeans-init-1"><span class="std std-numref">Fig. 9.7</span></a></p>
<figure class="align-default" id="toy-kmeans-init-1" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-407f7989abf049b1a5ea5f5aee2b4639.vega-embed</ins><del>#altair-viz-995a0537f8704c70aee1468deb580501.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-407f7989abf049b1a5ea5f5aee2b4639.vega-embed</ins><del>#altair-viz-995a0537f8704c70aee1468deb580501.vega-embed</del> details,
  <ins>#altair-viz-407f7989abf049b1a5ea5f5aee2b4639.vega-embed</ins><del>#altair-viz-995a0537f8704c70aee1468deb580501.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-407f7989abf049b1a5ea5f5aee2b4639"><div id="altair-viz-995a0537f8704c70aee1468deb580501"></div><img src="prerendered/toy-kmeans-init-1.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.7 </span><span class="caption-text">Random initialization of labels.
Each cluster is depicted as a different color and shape.</span><a class="headerlink" href="#toy-kmeans-init-1" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p id="index-13">Then K-means consists of two major steps that attempt to minimize the
sum of WSSDs over all the clusters, i.e., the <em>total WSSD</em>:</p>
<ol class="arabic simple">
<li><p><strong>Center update:</strong> Compute the center of each cluster.</p></li>
<li><p><strong>Label update:</strong> Reassign each data point to the cluster with the nearest center.</p></li>
</ol>
<p>These two steps are repeated until the cluster assignments no longer change.
We show what the first three iterations of K-means would look like in
<a class="reference internal" href="#toy-kmeans-iter-1"><span class="std std-numref">Fig. 9.8</span></a>. Each row corresponds to an iteration,
where the left column depicts the center update,
and the right column depicts the label update (i.e., the reassignment of data to clusters).</p>
<figure class="align-default" id="toy-kmeans-iter-1" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-ca768ff2f00246c49e2660252e239846.vega-embed</ins><del>#altair-viz-b2815ba93bef4fa38226691b2f69e161.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-ca768ff2f00246c49e2660252e239846.vega-embed</ins><del>#altair-viz-b2815ba93bef4fa38226691b2f69e161.vega-embed</del> details,
  <ins>#altair-viz-ca768ff2f00246c49e2660252e239846.vega-embed</ins><del>#altair-viz-b2815ba93bef4fa38226691b2f69e161.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-ca768ff2f00246c49e2660252e239846"><div id="altair-viz-b2815ba93bef4fa38226691b2f69e161"></div><img src="prerendered/toy-kmeans-iter-1.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.8 </span><span class="caption-text">First three iterations of K-means clustering on the <code class="docutils literal notranslate"><span class="pre">penguins_standardized</span></code> example data set. Each pair of plots corresponds to an iteration. Within the pair, the first plot depicts the center update, and the second plot depicts the reassignment of data to clusters. Cluster centers are indicated by larger points that are outlined in black.</span><a class="headerlink" href="#toy-kmeans-iter-1" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p>Note that at this point, we can terminate the algorithm since none of the assignments changed
in the third iteration; both the centers and labels will remain the same from this point onward.</p>
<div class="admonition note" id="index-14">
<p class="admonition-title">Note</p>
<p>Is K-means <em>guaranteed</em> to stop at some point, or could it iterate forever? As it turns out,
thankfully, the answer is that K-means is guaranteed to stop after <em>some</em> number of iterations. For the interested reader, the
logic for this has three steps: (1) both the label update and the center update decrease total WSSD in each iteration,
(2) the total WSSD is always greater than or equal to 0, and (3) there are only a finite number of possible
ways to assign the data to clusters. So at some point, the total WSSD must stop decreasing, which means none of the assignments
are changing, and the algorithm terminates.</p>
</div>
</section>
<section id="random-restarts">
<h3><span class="section-number">9.5.3. </span>Random restarts<a class="headerlink" href="#random-restarts" title="Permalink to this heading">#</a></h3>
<p id="index-15">Unlike the classification and regression models we studied in previous chapters, K-means can get “stuck” in a bad solution.
For example, <a class="reference internal" href="#toy-kmeans-bad-init-1"><span class="std std-numref">Fig. 9.9</span></a> illustrates an unlucky random initialization by K-means.</p>
<figure class="align-default" id="toy-kmeans-bad-init-1" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-000ab783a994436aa2d24bc3f2dc6a7b.vega-embed</ins><del>#altair-viz-3a29443d52a840abaef5830e8423206c.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-000ab783a994436aa2d24bc3f2dc6a7b.vega-embed</ins><del>#altair-viz-3a29443d52a840abaef5830e8423206c.vega-embed</del> details,
  <ins>#altair-viz-000ab783a994436aa2d24bc3f2dc6a7b.vega-embed</ins><del>#altair-viz-3a29443d52a840abaef5830e8423206c.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-000ab783a994436aa2d24bc3f2dc6a7b"><div id="altair-viz-3a29443d52a840abaef5830e8423206c"></div><img src="prerendered/toy-kmeans-bad-init-1.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.9 </span><span class="caption-text">Random initialization of labels.</span><a class="headerlink" href="#toy-kmeans-bad-init-1" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p><a class="reference internal" href="#toy-kmeans-bad-iter-1"><span class="std std-numref">Fig. 9.10</span></a> shows what the iterations of K-means would look like with the unlucky random initialization shown in <a class="reference internal" href="#toy-kmeans-bad-init-1"><span class="std std-numref">Fig. 9.9</span></a></p>
<figure class="align-default" id="toy-kmeans-bad-iter-1" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-b73d919c06294997985842ab71e984d2.vega-embed</ins><del>#altair-viz-d3b5bdf8e47644f2832954bf3b64588e.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-b73d919c06294997985842ab71e984d2.vega-embed</ins><del>#altair-viz-d3b5bdf8e47644f2832954bf3b64588e.vega-embed</del> details,
  <ins>#altair-viz-b73d919c06294997985842ab71e984d2.vega-embed</ins><del>#altair-viz-d3b5bdf8e47644f2832954bf3b64588e.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-b73d919c06294997985842ab71e984d2"><div id="altair-viz-d3b5bdf8e47644f2832954bf3b64588e"></div><img src="prerendered/toy-kmeans-bad-iter-1.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.10 </span><span class="caption-text">First four iterations of K-means clustering on the <code class="docutils literal notranslate"><span class="pre">penguins_standardized</span></code> example data set with a poor random initialization. Each pair of plots corresponds to an iteration. Within the pair, the first plot depicts the center update, and the second plot depicts the reassignment of data to clusters. Cluster centers are indicated by larger points that are outlined in black.</span><a class="headerlink" href="#toy-kmeans-bad-iter-1" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p>This looks like a relatively bad clustering of the data, but K-means cannot improve it.
To solve this problem when clustering data using K-means, we should randomly re-initialize the labels a few times, run K-means for each initialization,
and pick the clustering that has the lowest final total WSSD.</p>
</section>
<section id="choosing-k">
<h3><span class="section-number">9.5.4. </span>Choosing K<a class="headerlink" href="#choosing-k" title="Permalink to this heading">#</a></h3>
<p>In order to cluster data using K-means,
we also have to pick the number of clusters, K.
But unlike in classification, we have no response variable
and cannot perform cross-validation with some measure of model prediction error.
Further, if K is chosen too small, then multiple clusters get grouped together;
if K is too large, then clusters get subdivided.
In both cases, we will potentially miss interesting structure in the data.
<a class="reference internal" href="#toy-kmeans-vary-k-1"><span class="std std-numref">Fig. 9.11</span></a> illustrates the impact of K
on K-means clustering of our penguin flipper and bill length data
by showing the different clusterings for K’s ranging from 1 to 9.</p>
<figure class="align-default" id="toy-kmeans-vary-k-1" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-5f43e89ad0a34d31b5828d59056112fe.vega-embed</ins><del>#altair-viz-26107b89fe43485583012e5ed43a0387.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-5f43e89ad0a34d31b5828d59056112fe.vega-embed</ins><del>#altair-viz-26107b89fe43485583012e5ed43a0387.vega-embed</del> details,
  <ins>#altair-viz-5f43e89ad0a34d31b5828d59056112fe.vega-embed</ins><del>#altair-viz-26107b89fe43485583012e5ed43a0387.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-5f43e89ad0a34d31b5828d59056112fe"><div id="altair-viz-26107b89fe43485583012e5ed43a0387"></div><img src="prerendered/toy-kmeans-vary-k-1.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.11 </span><span class="caption-text">Clustering of the penguin data for K clusters ranging from 1 to 9. Cluster centers are indicated by larger points that are outlined in black.</span><a class="headerlink" href="#toy-kmeans-vary-k-1" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p id="index-16">If we set K less than 3, then the clustering merges separate groups of data; this causes a large
total WSSD, since the cluster center (denoted by large shapes with black outlines) is not close to any of the data in the cluster. On
the other hand, if we set K greater than 3, the clustering subdivides subgroups of data; this does indeed still
decrease the total WSSD, but by only a <em>diminishing amount</em>. If we plot the total WSSD versus the number of
clusters, we see that the decrease in total WSSD levels off (or forms an “elbow shape”) when we reach roughly
the right number of clusters (<a class="reference internal" href="#toy-kmeans-elbow"><span class="std std-numref">Fig. 9.12</span></a>).</p>
<figure class="align-default" id="toy-kmeans-elbow" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-a32cf84e6f1b42ad8aeb6a9123153915.vega-embed</ins><del>#altair-viz-326c9a98affc473ab0e7b1e6e9c72798.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-a32cf84e6f1b42ad8aeb6a9123153915.vega-embed</ins><del>#altair-viz-326c9a98affc473ab0e7b1e6e9c72798.vega-embed</del> details,
  <ins>#altair-viz-a32cf84e6f1b42ad8aeb6a9123153915.vega-embed</ins><del>#altair-viz-326c9a98affc473ab0e7b1e6e9c72798.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-a32cf84e6f1b42ad8aeb6a9123153915"><div id="altair-viz-326c9a98affc473ab0e7b1e6e9c72798"></div><img src="prerendered/toy-kmeans-elbow.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.12 </span><span class="caption-text">Total WSSD for K clusters ranging from 1 to 9.</span><a class="headerlink" href="#toy-kmeans-elbow" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
</section>
</section>
<section id="k-means-in-python">
<h2><span class="section-number">9.6. </span>K-means in Python<a class="headerlink" href="#k-means-in-python" title="Permalink to this heading">#</a></h2>
<span class="target" id="index-17"></span><p id="index-18">We can perform K-means in Python using a workflow similar to those
in the earlier classification and regression chapters.
Returning to the original (unstandardized) <code class="docutils literal notranslate"><span class="pre">penguins</span></code> data,
recall that K-means clustering uses straight-line distance to decide which points are similar to
each other. Therefore, the <em>scale</em> of each of the variables in the data
will influence which cluster data points end up being assigned.
Variables with a large scale will have a much larger
effect on deciding cluster assignment than variables with a small scale.
To address this problem, we typically standardize our data before clustering,
which ensures that each variable has a mean of 0 and standard deviation of 1.
The <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> function in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> can be used to do this.</p>
<div class="cell docutils container" id="index-19">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>

<span class="c1"># Output dataframes instead of arrays</span>
<span class="n">set_config</span><span class="p">(</span><span class="n">transform_output</span><span class="o">=</span><span class="s2">"pandas"</span><span class="p">)</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="p">[</span><span class="s2">"bill_length_mm"</span><span class="p">,</span> <span class="s2">"flipper_length_mm"</span><span class="p">]),</span>
    <span class="n">verbose_feature_names_out</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">preprocessor</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div class="sk-top-container" id="sk-container-id-1"><div class="sk-text-repr-fallback"><pre>ColumnTransformer(transformers=[('standardscaler', StandardScaler(),
                                 ['bill_length_mm', 'flipper_length_mm'])],
                  verbose_feature_names_out=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br/>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-1">ColumnTransformer</label><div class="sk-toggleable__content"><pre>ColumnTransformer(transformers=[('standardscaler', StandardScaler(),
                                 ['bill_length_mm', 'flipper_length_mm'])],
                  verbose_feature_names_out=False)</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-2">standardscaler</label><div class="sk-toggleable__content"><pre>['bill_length_mm', 'flipper_length_mm']</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-3">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<p>To indicate that we are performing K-means clustering, we will create a <code class="docutils literal notranslate"><span class="pre">KMeans</span></code>
model object. It takes at
least one argument: the number of clusters <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code>, which we set to 3.</p>
<div class="cell docutils container" id="index-20">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">kmeans</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div class="sk-top-container" id="sk-container-id-2"><div class="sk-text-repr-fallback"><pre>KMeans(n_clusters=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br/>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator sk-toggleable"><input checked="" class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-4">KMeans</label><div class="sk-toggleable__content"><pre>KMeans(n_clusters=3)</pre></div></div></div></div></div></div></div>
</div>
<p id="index-21">To actually run the K-means clustering, we combine the preprocessor and model object
in a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>, and use the <code class="docutils literal notranslate"><span class="pre">fit</span></code> function. Note that the K-means
algorithm uses a random initialization of assignments, but since we set
the random seed in the beginning of this chapter, the clustering will be reproducible.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">penguin_clust</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">)</span>
<span class="n">penguin_clust</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">penguins</span><span class="p">)</span>
<span class="n">penguin_clust</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div class="sk-top-container" id="sk-container-id-3"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('columntransformer',
                 ColumnTransformer(transformers=[('standardscaler',
                                                  StandardScaler(),
                                                  ['bill_length_mm',
                                                   'flipper_length_mm'])],
                                   verbose_feature_names_out=False)),
                ('kmeans', KMeans(n_clusters=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br/>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-5">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('columntransformer',
                 ColumnTransformer(transformers=[('standardscaler',
                                                  StandardScaler(),
                                                  ['bill_length_mm',
                                                   'flipper_length_mm'])],
                                   verbose_feature_names_out=False)),
                ('kmeans', KMeans(n_clusters=3))])</pre></div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-6">columntransformer: ColumnTransformer</label><div class="sk-toggleable__content"><pre>ColumnTransformer(transformers=[('standardscaler', StandardScaler(),
                                 ['bill_length_mm', 'flipper_length_mm'])],
                  verbose_feature_names_out=False)</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-7">standardscaler</label><div class="sk-toggleable__content"><pre>['bill_length_mm', 'flipper_length_mm']</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-8">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox"/><label class="sk-toggleable__label sk-toggleable__label-arrow" for="sk-estimator-id-9">KMeans</label><div class="sk-toggleable__content"><pre>KMeans(n_clusters=3)</pre></div></div></div></div></div></div></div></div></div>
</div>
<p id="index-22">The fit <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> object—which is the second item in the
pipeline, and can be accessed as <code class="docutils literal notranslate"><span class="pre">penguin_clust[1]</span></code>—has a lot of information
that can be used to visualize the clusters, pick K, and evaluate the total WSSD.
Let’s start by visualizing the clusters as a colored scatter plot! In
order to do that, we first need to augment our
original <code class="docutils literal notranslate"><span class="pre">penguins</span></code> data frame with the cluster assignments.
We can access these using the <code class="docutils literal notranslate"><span class="pre">labels_</span></code> attribute of the clustering object
(“labels” is a common alternative term to “assignments” in clustering), and
add them to the data frame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguins</span><span class="p">[</span><span class="s2">"cluster"</span><span class="p">]</span> <span class="o">=</span> <span class="n">penguin_clust</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">penguins</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>bill_length_mm</th>
<th>flipper_length_mm</th>
<th>cluster</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>39.2</td>
<td>196</td>
<td>1</td>
</tr>
<tr>
<th>1</th>
<td>36.5</td>
<td>182</td>
<td>1</td>
</tr>
<tr>
<th>2</th>
<td>34.5</td>
<td>187</td>
<td>1</td>
</tr>
<tr>
<th>3</th>
<td>36.7</td>
<td>187</td>
<td>1</td>
</tr>
<tr>
<th>4</th>
<td>38.1</td>
<td>181</td>
<td>1</td>
</tr>
<tr>
<th>5</th>
<td>39.2</td>
<td>190</td>
<td>1</td>
</tr>
<tr>
<th>6</th>
<td>36.0</td>
<td>195</td>
<td>1</td>
</tr>
<tr>
<th>7</th>
<td>37.8</td>
<td>193</td>
<td>1</td>
</tr>
<tr>
<th>8</th>
<td>46.5</td>
<td>213</td>
<td>2</td>
</tr>
<tr>
<th>9</th>
<td>46.1</td>
<td>215</td>
<td>2</td>
</tr>
<tr>
<th>10</th>
<td>47.8</td>
<td>215</td>
<td>2</td>
</tr>
<tr>
<th>11</th>
<td>45.0</td>
<td>220</td>
<td>2</td>
</tr>
<tr>
<th>12</th>
<td>49.1</td>
<td>212</td>
<td>2</td>
</tr>
<tr>
<th>13</th>
<td>43.3</td>
<td>208</td>
<td>2</td>
</tr>
<tr>
<th>14</th>
<td>46.0</td>
<td>195</td>
<td>0</td>
</tr>
<tr>
<th>15</th>
<td>46.7</td>
<td>195</td>
<td>0</td>
</tr>
<tr>
<th>16</th>
<td>52.2</td>
<td>197</td>
<td>0</td>
</tr>
<tr>
<th>17</th>
<td>46.8</td>
<td>189</td>
<td>0</td>
</tr>
</tbody>
</table>
</div></div></div>
</div>
<p>Now that we have the cluster assignments included in the <code class="docutils literal notranslate"><span class="pre">penguins</span></code> data frame, we can
visualize them as shown in <a class="reference internal" href="#cluster-plot"><span class="std std-numref">Fig. 9.13</span></a>.
Note that we are plotting the <em>un-standardized</em> data here; if we for some reason wanted to
visualize the <em>standardized</em> data, we would need to use the <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> functions
on the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> preprocessor directly to obtain that first.
As in <a class="reference internal link-to-diff" href="viz.html#viz"><span class="std std-numref">Chapter 4</span></a>,
adding the <code class="docutils literal notranslate"><span class="pre">:N</span></code> suffix ensures that <code class="docutils literal notranslate"><span class="pre">altair</span></code>
will treat the <code class="docutils literal notranslate"><span class="pre">cluster</span></code> variable as a nominal/categorical variable, and
hence use a discrete color map for the visualization.</p>
<div class="cell docutils container" id="index-23">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cluster_plot</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">penguins</span><span class="p">)</span><span class="o">.</span><span class="n">mark_circle</span><span class="p">()</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">"flipper_length_mm"</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Flipper Length"</span><span class="p">)</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">zero</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">y</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s2">"bill_length_mm"</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Bill Length"</span><span class="p">)</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">zero</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">color</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Color</span><span class="p">(</span><span class="s2">"cluster:N"</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Cluster"</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="cluster-plot" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-1435a0c56d3b40e1bf2ac68c0c3772e9.vega-embed</ins><del>#altair-viz-b842ecdb08e04822be26541cbd17e7b2.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-1435a0c56d3b40e1bf2ac68c0c3772e9.vega-embed</ins><del>#altair-viz-b842ecdb08e04822be26541cbd17e7b2.vega-embed</del> details,
  <ins>#altair-viz-1435a0c56d3b40e1bf2ac68c0c3772e9.vega-embed</ins><del>#altair-viz-b842ecdb08e04822be26541cbd17e7b2.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-1435a0c56d3b40e1bf2ac68c0c3772e9"><div id="altair-viz-b842ecdb08e04822be26541cbd17e7b2"></div><img src="prerendered/cluster-plot.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.13 </span><span class="caption-text">The data colored by the cluster assignments returned by K-means.</span><a class="headerlink" href="#cluster-plot" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<span class="target" id="index-24"></span><p id="index-25">As mentioned above,
we also need to select K
by finding where the “elbow” occurs in the plot of total WSSD versus the number of clusters.
The total WSSD is stored in the <code class="docutils literal notranslate"><span class="pre">.inertia_</span></code> attribute
of the clustering object (“inertia” is the term <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> uses to denote WSSD).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">penguin_clust</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inertia_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4.730719092276117
</pre></div>
</div>
</div>
</div>
<p>To calculate the total WSSD for a variety of Ks, we will
create a data frame that contains different values of <code class="docutils literal notranslate"><span class="pre">k</span></code>
and the WSSD of running K-means with each values of k.
To create this dataframe,
we will use what is called a “list comprehension” in Python,
where we repeat an operation multiple times
and return a list with the result.
Here is an examples of a list comprehension that stores the numbers 0-2 in a list:</p>
<div class="cell docutils container" id="index-26">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0, 1, 2]
</pre></div>
</div>
</div>
</div>
<p>We can change the variable <code class="docutils literal notranslate"><span class="pre">n</span></code> to be called whatever we prefer
and we can also perform any operation we want as part of the list comprehension.
For example,
we could square all the numbers from 1-4 and store them in a list:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">number</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">number</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1, 4, 9, 16]
</pre></div>
</div>
</div>
</div>
<p>Next, we will use this approach to compute the WSSD for the K-values 1 through 9.
For each value of K,
we create a new <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> model
and wrap it in a <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> pipeline
with the preprocessor we created earlier.
We store the WSSD values in a list that we will use to create a dataframe
of both the K-values and their corresponding WSSDs.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We are creating the variable <code class="docutils literal notranslate"><span class="pre">ks</span></code> to store the range of possible k-values,
so that we only need to change this range in one place
if we decide to change which values of k we want to explore.
Otherwise it would be easy to forget to update it
in either the list comprehension or in the data frame assignment.
If you are using a value multiple times,
it is always the safest to assign it to a variable name for reuse.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ks</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">wssds</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">make_pipeline</span><span class="p">(</span>
    	<span class="n">preprocessor</span><span class="p">,</span>
    	<span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>  <span class="c1"># Create a new KMeans model with `k` clusters</span>
    <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">penguins</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">inertia_</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span>
<span class="p">]</span>

<span class="n">penguin_clust_ks</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">"k"</span><span class="p">:</span> <span class="n">ks</span><span class="p">,</span>
    <span class="s2">"wssd"</span><span class="p">:</span> <span class="n">wssds</span><span class="p">,</span>
<span class="p">})</span>

<span class="n">penguin_clust_ks</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>k</th>
<th>wssd</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>1</td>
<td>36.000000</td>
</tr>
<tr>
<th>1</th>
<td>2</td>
<td>11.576264</td>
</tr>
<tr>
<th>2</th>
<td>3</td>
<td>4.730719</td>
</tr>
<tr>
<th>3</th>
<td>4</td>
<td>3.343613</td>
</tr>
<tr>
<th>4</th>
<td>5</td>
<td>2.362131</td>
</tr>
<tr>
<th>5</th>
<td>6</td>
<td>1.678383</td>
</tr>
<tr>
<th>6</th>
<td>7</td>
<td>1.293320</td>
</tr>
<tr>
<th>7</th>
<td>8</td>
<td>0.975016</td>
</tr>
<tr>
<th>8</th>
<td>9</td>
<td>0.785232</td>
</tr>
</tbody>
</table>
</div></div></div>
</div>
<p>Now that we have <code class="docutils literal notranslate"><span class="pre">wssd</span></code> and <code class="docutils literal notranslate"><span class="pre">k</span></code> as columns in a data frame, we can make a line plot
(<a class="reference internal" href="#elbow-plot"><span class="std std-numref">Fig. 9.14</span></a>) and search for the “elbow” to find which value of K to use.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elbow_plot</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">penguin_clust_ks</span><span class="p">)</span><span class="o">.</span><span class="n">mark_line</span><span class="p">(</span><span class="n">point</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">"k"</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Number of clusters"</span><span class="p">),</span>
    <span class="n">y</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s2">"wssd"</span><span class="p">)</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Total within-cluster sum of squares"</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<figure class="align-default" id="elbow-plot" style="width: 700px">
<div class="output text_html">
<style>
  <ins>#altair-viz-23356599a88b4012ac5de1a169cc25d8.vega-embed</ins><del>#altair-viz-f650910ac1c64ac7bd093238912c7e57.vega-embed</del> {
    width: 100%;
    display: flex;
  }

  <ins>#altair-viz-23356599a88b4012ac5de1a169cc25d8.vega-embed</ins><del>#altair-viz-f650910ac1c64ac7bd093238912c7e57.vega-embed</del> details,
  <ins>#altair-viz-23356599a88b4012ac5de1a169cc25d8.vega-embed</ins><del>#altair-viz-f650910ac1c64ac7bd093238912c7e57.vega-embed</del> details summary {
    position: relative;
  }
</style>
<div id="altair-viz-23356599a88b4012ac5de1a169cc25d8"><div id="altair-viz-f650910ac1c64ac7bd093238912c7e57"></div><img src="prerendered/elbow-plot.png"/>
</div><figcaption>
<p><span class="caption-number">Fig. 9.14 </span><span class="caption-text">A plot showing the total WSSD versus the number of clusters.</span><a class="headerlink" href="#elbow-plot" title="Permalink to this image">#</a></p>
</figcaption>
</div></figure>
<p>It looks like three clusters is the right choice for this data,
since that is where the “elbow” of the line is the most distinct.
In the plot,
you can also see that the WSSD is always decreasing,
as we would expect when we add more clusters.
However,
it is possible to have an elbow plot
where the WSSD increases at one of the steps,
causing a small bump in the line.
This is because K-means can get “stuck” in a bad solution
due to an unlucky initialization of the initial center positions
as we mentioned earlier in the chapter.</p>
<div class="admonition note" id="index-27">
<p class="admonition-title">Note</p>
<p>It is rare that the implementation of K-means from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>
gets stuck in a bad solution, because <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> tries to choose
the initial centers carefully to prevent this from happening.
If you still find yourself in a situation where you have a bump in the elbow plot,
you can increase the <code class="docutils literal notranslate"><span class="pre">n_init</span></code> parameter
when creating the <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> object, e.g., <code class="docutils literal notranslate"><span class="pre">KMeans(n_clusters=k,</span> <span class="pre">n_init=10)</span></code>, to try more different random center initializations.
The larger the value the better from an analysis perspective,
but there is a trade-off that doing many clusterings could take a long time.</p>
</div>
</section>
<section id="exercises">
<h2><span class="section-number">9.7. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">#</a></h2>
<p>Practice exercises for the material covered in this chapter<ins class="diff"> </ins>can be found in the<ins class="diff">accompanying</ins> <del class="diff">accompanying</del><a class="reference external" href="https://worksheets.python.datasciencebook.ca">worksheets repository</a><ins class="diff"> in</ins>
<del class="diff">in </del>the “Clustering” row.<ins class="diff"> </ins>You can <ins class="diff">preview</ins><del class="diff">launch</del> <ins class="diff">anon-interactive</ins><del class="diff">an</del> <del class="diff">interactive </del>version of the worksheet <ins class="diff">for</ins><del class="diff">in</del> <ins class="diff">this</ins><del class="diff">your</del> <ins class="diff">chapter</ins><del class="diff">browser</del> by clicking <ins class="diff">“view</ins><del class="diff">the “launch binder” button.</del>
<ins class="diff">worksheet.”</ins><del class="diff">You</del> <ins class="diff">To</ins><del class="diff">can</del> <ins class="diff">work</ins><del class="diff">also</del> <ins class="diff">on</ins><del class="diff">preview</del> <ins class="diff">the</ins><del class="diff">a</del> <ins class="diff">exercises</ins><del class="diff">non-interactive</del> <ins class="diff">interactively,</ins><del class="diff">version</del> <ins class="diff">follow</ins><del class="diff">of</del> the <ins class="diff">instructions</ins><del class="diff">worksheet</del> <ins class="diff">in</ins><del class="diff">by clicking “view worksheet.”</del>
<ins class="diff">the</ins><del class="diff">If</del> <ins class="diff">worksheets</ins><del class="diff">you</del> <ins class="diff">repository</ins><del class="diff">instead</del> <del class="diff">decide </del>to download <ins class="diff">all</ins><del class="diff">the</del> <ins class="diff">worksheets,</ins><del class="diff">worksheet</del> and <del class="diff">run it on your own machine,make sure to </del>follow the<del class="diff"> </del>instructions for computer setup<ins class="diff"> </ins>found in <a class="reference internal link-to-diff" href="setup.html#move-to-your-own-machine"><span class="std std-numref">Chapter 13</span></a>. This will ensure<del class="diff"> </del>that the automated feedback<ins class="diff"> </ins>and guidance that the worksheets provide will<del class="diff"> </del>function as intended.</p>
</section>
<section id="additional-resources">
<h2><span class="section-number">9.8. </span>Additional resources<a class="headerlink" href="#additional-resources" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Chapter 10 of <em>An Introduction to Statistical
Learning</em> <span id="id6">[<a class="reference internal link-to-diff" href="regression2.html#id21" title="Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An Introduction to Statistical Learning. Springer, 1st edition, 2013. URL: https://www.statlearning.com/.">James <em>et al.</em>, 2013</a>]</span> provides a
great next stop in the process of learning about clustering and unsupervised
learning in general. In the realm of clustering specifically, it provides a
great companion introduction to K-means, but also covers <em>hierarchical</em>
clustering for when you expect there to be subgroups, and then subgroups within
subgroups, etc., in your data. In the realm of more general unsupervised
learning, it covers <em>principal components analysis (PCA)</em>, which is a very
popular technique for reducing the number of predictors in a data set.</p></li>
</ul>
</section>
<section id="references">
<h2><span class="section-number">9.9. </span>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<div class="docutils container" id="id7">
<dl class="citation">
<dt class="label" id="id11"><span class="brackets"><a class="fn-backref" href="#id5">GWF14</a></span></dt>
<dd><p>Kristen Gorman, Tony Williams, and William Fraser. Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus pygoscelis). <em>PLoS ONE</em>, 2014.</p>
</dd>
<dt class="label" id="id41"><span class="brackets"><a class="fn-backref" href="#id4">HHG20</a></span></dt>
<dd><p>Allison Horst, Alison Hill, and Kristen Gorman. <em>palmerpenguins: Palmer Archipelago penguin data</em>. 2020. R package version 0.1.0. URL: <a class="reference external" href="https://allisonhorst.github.io/palmerpenguins/">https://allisonhorst.github.io/palmerpenguins/</a>.</p>
</dd>
<dt class="label" id="id26"><span class="brackets"><a class="fn-backref" href="#id6">JWHT13</a></span></dt>
<dd><p>Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. <em>An Introduction to Statistical Learning</em>. Springer, 1st edition, 2013. URL: <a class="reference external" href="https://www.statlearning.com/">https://www.statlearning.com/</a>.</p>
</dd>
<dt class="label" id="id12"><span class="brackets"><a class="fn-backref" href="#id3">Llo82</a></span></dt>
<dd><p>Stuart Lloyd. Least square quantization in PCM. <em>IEEE Transactions on Information Theory</em>, 28(2):129–137, 1982. Originally released as a Bell Telephone Laboratories Paper in 1957.</p>
</dd>
</dl>
</div>
</section>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="prev-next-footer">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev link-to-diff" href="regression2.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title"><span class="section-number">8. </span>Regression II: linear regression</p>
</div>
</a>
<a class="right-next link-to-diff" href="inference.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title"><span class="section-number">10. </span>Statistical inference</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage">
<i class="fa-solid fa-list"></i> Contents
  </div>
<nav class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">9.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-learning-objectives">9.2. Chapter learning objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">9.3. Clustering</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-illustrative-example">9.4. An illustrative example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means">9.5. K-means</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-cluster-quality">9.5.1. Measuring cluster quality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-clustering-algorithm">9.5.2. The clustering algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-restarts">9.5.3. Random restarts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#choosing-k">9.5.4. Choosing K</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means-in-python">9.6. K-means in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">9.7. Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-resources">9.8. Additional resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">9.9. References</a></li>
</ul>
</nav></div>
</div></div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Tiffany Timbers, Trevor Campbell, Melissa Lee, Joel Ostblom, and Lindsey Heagy
</p>
</div>
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2022.
      <br/>
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>
<footer class="bd-footer">
</footer>
</body>
</html>